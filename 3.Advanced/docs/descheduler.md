前： [ClusterAutoscaler](ClusterAutoscaler.md)  

---

# descheduler

deschedulerはクラスタを監視し、ルールに基づきPodを削除する機能です。この機能は削除されたPodがセルフ・ヒーリングで再配置されることを利用した機能です。deschedulerはK8s内にコントローラの役割を担うPodをデプロイして機能します。  
Podの起動先ノードを決めることをK8sではスケジュールと言います。このスケジュールはマスターコンポーネントであるkube-schedulerにより行われます。スケジュールはPodが起動するタイミングでしか行われません。例えば、ノード障害などが発生し、あるノードで動いていたPodが別のノードに退避されたとします。その後、ノードを再度クラスタに参加させてもそのノードには何もPodが起動されません。（もしノードが参加した時点でPending状態のPodがあれば起動されます。）  
PodのスケジュールはPod起動時にしか行われないため、このようにあとからノードを追加しても思うように負荷が分散されていない状況が起こります。これを防止する機能がdeschedulerです。deschedulerは定期的にクラスタを監視し、ルールに基づいてPodを削除します。Podを削除するとセルフ・ヒーリングされます。セルフヒーリング時にマスターコンポーネントのkube-schedulerによりノードの負荷状況などを考慮して再スケジュールが行われます。

# 演習

1. ワーカーノード2台の状態から作業する。

1. 以下を満たすマニフェストを作成しデプロイしてください。

   - 要件
     - Deployment
       - イメージは何でもよい
       - replicas:10

1. 各Podが起動しているノードを一覧で表示し、2つのノードに分散配置されていることを確認してください。

1. どちらかのノードを停止してください。（停止の方法は何でも良いです）

1. ノード停止から1分ほどしてからPodの起動ノードを確認してください。1つのノードに片寄って配置されていることを確認してください。

1. ワーカーノードを1台クラスタに再参加さしてください。（ワーカーをAutoScalingGroupで構成している場合、しばらく待っていれば自動的に追加されると思います。）

1. ワーカー2台の状態に戻ってもPodの起動ノードが片寄った状態のままで有ることを確認してください。

1. 以下コマンドで必要なマニフェストが含まれるgitリポジトリをクローンしてください。

   ``` sh
   git clone https://github.com/kubernetes-sigs/descheduler.git
   ```

1. 以下コマンドで必要なマニフェストをapply

   ``` sh
   kubectl create -f kubernetes/base/rbac.yaml
   kubectl create -f kubernetes/base/configmap.yaml
   kubectl create -f kubernetes/cronjob/cronjob.yaml
   ```

1. 2分ほどたってからPodの起動ノードを確認し、2ノードに分散されていることを確認してください。

1. 作成したリソースを削除してください。

以上で本演習は終了です。
具体的な操作およびその結果に関する回答例は[こちら](../ans/descheduler_answer.md)にあります。
具体的な操作方法がわからなかった場合や、想定した結果にならなかった場合などに参照してください。

---

次： [IngressController](IngressController.md)  
